<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [Motivation](#motivation)
- [Goals](#goals)
- [Non-Goals](#non-goals)
- [API](#api)
  - [Resulting AlluxioRuntime](#resulting-alluxioruntime)
  - [Resulting Alluxio Helm Chart](#resulting-alluxio-helm-chart)
- [Workflow](#workflow)
- [Alternatives Considered](#alternatives-considered)
- [Commits](#commits)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

## Motivation
当使用HDFS作为Alluxio的UFS时, 如果HDFS使用**非默认**的配置,那么可能需要将该配置文件(e.g. `hdfs-site.xml`或`core-site.xml`)传递给Alluxio. Fluid目前不支持这样的配置方式, 因此拥有特殊配置的HDFS集群的用户将难以使用Fluid进行Alluxio分布式缓存引擎的部署.

## Goals
* 支持HDFS的特殊配置

## Non-Goals
* 暂时仅支持HDFS的特殊配置,不适用于其他Alluxio的底层存储集成
* 仅支持`hdfs-site.xml`和`core-site.xml`两个HDFS相关的配置文件

## API

### Resulting AlluxioRuntime

```yaml
apiVersion: data.fluid.io/v1alpha1
kind: AlluxioRuntime
metadata:
  name: hadoop
  namespace: default
spec:
  ...
  hadoopConfig: hdfs-configmap
  ...
```

在AlluxioRuntime中添加`spec.hadoopConfig`属性,该属性应当指向一个用户预先创建好的ConfigMap, 并且该ConfigMap须和待创建的AlluxioRuntime处于同一命名空间中.在该ConfigMap中:

- 可以包括以"hdfs-site.xml"为键,以配置文件`hdfs-site.xml`的内容为值的键值对
- 可以包括以"core-site.xml"为键,以配置文件`core-site.xml`的内容为值的键值对
- 其他无关的键值对,将被忽略

上述ConfigMap中存在的"hdfs-site.xml"或者"core-site.xml"键值对将会在Alluxio集群启动时,以文件方式挂载至Alluxio的各个容器中.


### Resulting Alluxio Helm Chart

`values.yaml`中增加如下内容:

```yaml
hadoopConfig:
  configMap: hdfs-configmap
  includeHdfsSite: true
  includeCoreSite: true
```

Alluxio Helm Chart模板(e.g. `master/statefulset.yaml`以及`worker/daemonset.yaml`)中增加与ConfigMap挂载相关的配置:

```yaml
containers:
  - name: xxx
    ...
    volumeMounts:
    ...
    - name: hdfs-config
      mountPath: "/hdfs-config"
      readOnly: true

volumes:
  ...
  - name: hdfs-config
    configMap:
      name: {{ .Values.hadoopConfig.configMap }}
      items:
      {{ if .Values.hadoopConfig.includeHdfsSite }}
      - key: hdfs-site.xml
        path: "hdfs-site.xml"
      {{ end }}
      {{ if .Values.hadoopConfig.includeCoreSite }}
      - key: core-site.xml
        path: "core-site.xml"
      {{ end }}
  ...
```

上述配置将在创建出的Alluxio Master以及Alluxio Worker Pod的各个容器中以ConfigMap挂载的方式创建 `/hdfs-config/hdfs-site.xml`以及`/hdfs-config/core-site.xml`. 

在Alluxio的容器中挂载用户定义的上述HDFS配置文件后,仅需设置`alluxio.underfs.hdfs.configuration=/hdfs-config/hdfs-site.xml:/hdfs-config/core-site.xml`即可启用Alluxio对HDFS特殊配置的支持


## Workflow

1. 用户根据本地的`hdfs-site.xml`以及`core-site.xml`创建ConfigMap

    用户可通过`--from-file`快速创建一个ConfigMap:
    ```
    $ kubectl create configmap hdfs-configmap --from-file /path/to/hdfs-site.xml --from-file /path/to/core-site.xml
    ```

    创建出来的ConfigMap将有类似如下结构:
    ```
      Data
      ====
      core-site.xml:
      ----
      <?xml version="1.0" encoding="UTF-8"?>
      <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
      ...

      <configuration>
      </configuration>

      hdfs-site.xml:
      ----
      <?xml version="1.0" encoding="UTF-8"?>
      <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
      ...

      <configuration>

      </configuration>

    ```

2. 用户创建AlluxioRuntime时引用该ConfigMap

    创建类似如下的AlluxioRuntime:
    ```yaml
    apiVersion: data.fluid.io/v1alpha1
    kind: AlluxioRuntime
    metadata:
      name: hadoop
      namespace: default
    spec:
      ...
      hadoopConfig: hdfs-configmap
      ...
    ```

3. `alluxioruntime-controller`检查是否需要HDFS的特殊配置,并生成helm chart所需的`values.yaml`,以该`values.yaml`进行 helm install

    `alluxioruntime-controller`需要进行以下几个步骤:
    - 检查`spec.hadoopConfig`是否设置
    - 获取`spec.hadoopConfig`所引用的Configmap
    - 检查"hdfs-site.xml"或"core-site.xml"键值对是否存在
    - 根据键值对存在结果设定`alluxio.underfs.hdfs.configuration`
    - 生成`values.yaml`

5. Alluxio集群启动时读取HDFS相关配置文件.

## Alternatives Considered

使用Secret而不是ConfigMap完成上述过程.

## Commits


