# The affinity between Data Operation Pods in DataFlow

## Motivation
Currently, Fluid supports DataFlow, which allows multiple Data Operations to be executed sequentially. However, different data operation pods may run on different nodes, resulting in overall low performance:

- If subsequent data operations can run on the same node/zone/region as the previous data operations, it could potentially enhance the overall execution efficiency and data processing speed. This design strategy reduces data migration across different nodes and reduces network communication overhead, resulting in performance optimization.

## Goals

- Support the affinity inheritance of Pods for different Data Operations in the DataFlow, scheduling them to the same ***node/zone/region***, to improve the overall performance of DataFlow;
- Support different affinity inheritance strategies, default to `""` (empty value), keep the current schedule unchanged, optional value are `Require`or `Prefer`;
- Support setting the `Require`/`Prefer`node labels for affinity matching,  the default matching label is `kubernetes.io/hostname`;
## Design

### 0. Flow Chart

For the Reconcile logic of Data Operation, during the executing phase,  mainly added the following processes:

- Data Operation adds node information for the running Pod in its Status field;
- The affinity of the Data Operation Pod adds affinities that match from the previous Data Operation Status based on its Affinity Strategy;

![img](images/data_flow_affinity_flow_en.jpeg)



### 1. Data Operation Status adds runtime node information

When a Data Operation is running, the information about the node (such as the hostname of the node and the Region/Zone where the node is located) is added to the OperationStatus.

```go
type OperationStatus struct {
    // Added Field.
    // stores the operation pod's node info, key is a host label.
    // +optional
    NodeAffinityLabels map[string][string]
}
```

1. Fluid will add the tag information of `kubernetes.io/hostname`, `topology.kubernetes.io/zone`, and `topology.kubernetes.io/region` according to the node where the Operation Pod is located.

2. If user defines the  NodeAffinity in Operation Spec, Fluid will also match and record key-value pairs based on the labels of the node where the pod is located. And if the key does not exist on the node, it will not be recorded.
   - Regardless of whether the user-defined NodeSelectorOperator is `In/NotIn/Exists/Lt/.. `, which is later converted to the `In` type of NodeAffinity to be used by subsequent Operation；

3. <font color='red'>If an Operation is a distributed job with multiple pods, the node information  is not recorded.</font>

### 2. Data Operation adds an affinity schedule based on the runtime information of the previous Op

In the definition of DataOperation, need to add the following fields:
```go
// the referent operation
type OperationRef struct {
    // Added Field.
    // Namespace specifies the pod affinity strategy with the referent operation.
    // +optional
    AffinityStrategy *AffinityStrategy `json:"affinityStrategy,omitempty"`
}

// The following are all newly added codes.
type AffinityPolicy string

const (
	DefaultAffinityPolicy AffinityPolicy = ""
	RequireAffinityPolicy AffinityPolicy = "Require"
	PreferAffinityPolicy  AffinityPolicy = "Prefer"
)

type AffinityStrategy struct {
    // Policy one of: "", "Require", "Prefer"
    // +optional 
    Policy AffinityPolicy `json:policy,omitemtpy"`

    // Require define the matching label names when Policy is 'require'.
    // use "kubernetes.io/hostname" laby default.
    // +optional 
    Require []string `json:"require,omitempty"`
    
    // Require define the matching label names and weights when Policy is 'prefer'.
    // use "kubernetes.io/hostname" name and weight 100 by default.
    // +optional 
    Prefer  []Prefer `json:"prefer,omitempty"`
}

type Prefer struct {
    Name   string `json:"name"`
    Weight int    `json:"weight"`
}
```

### Affinity inheritance matching  logic
When generating the helm values file，Data Operation needs to **set the Affinity field of its own pod according to the node information of the previous DataOperation Status:**：

- This logic must be added to each implementation engine of each Data Operation;

**The formula for PodAffinity at the time of each Operation is as follows:**

- $PodAffinity(Op) = Op.Spec.Affinity + MatchAndGenerateAffinity(Op)$


```go
func MatchAndGenerateAffinity(current DataOperation) *corev1.Affinity {
    // If Op doesn't have a prepend,  returns nil
    if current.Spec.RunAfter == nil {
        return nil
    }
    // Obtain the node information of the pre-operation
    prevOpNodeLabels := getReferentOp(current.Spec.RunAfter).Status.NodeAffinityLabels
    
    policy := current.Spec.RunAfter.AffinityStratgey.Policy

    // 1. It is not configured by default and does not inherit any affinity from the previous operation
    if policy == "" {
        return nil
    }
    
    // There is no node location information in the previous Op Status
    if prevOpNodeLabels == nil {
        return nil
    }
    
    // 2. require Affinity inheritance
    if policy == "require" {
        // default affinity label of the node
        if current.Spec.RunAfter.AffinityStratgey.Require == nil {
            current.Spec.RunAfter.AffinityStratgey.Require = []string{
                "kubernetes.io/hostname"
            }
        }
        for _, label := range(current.Spec.RunAfter.AffinityStratgey.Require) {
            // match affinity by the label name
            value := prevOpNodeLabels[label]
            // transform to NodeSelectorTerm (require)
            return transfromToNodeSelectorTerm(label, value)
        }
    }
    
    // 3. prefer Affinity inheritance
    if policy == "prefer" {
        // default affinity label of the node
        if current.Spec.RunAfter.AffinityStratgey.Prefer == nil {
            current.Spec.RunAfter.AffinityStratgey.Prefer = []Prefer {
                {
                    Name: "kubernetes.io/hostname",
                    Weight: 100,
                },
            }
        }
        for _, prefer := range(current.Spec.RunAfter.AffinityStratgey.Prefer) {
            // match affinity by the label name
            value := prevOpNodeLabels[prefer.Name]
            // transform to PreferredSchedulingTerm
            return transfromToPreferredSchedulingTerm(prefer.Name, prefer.Weight, value)
        }
    }
}
```



### Example

Example 1：DataFlow: Op_A, Op_B，requires Op_B to run on the same node as Op_A;

```yaml
# Operation B configure the affinity policy as follows
metadata:
	name: B
spec:
	operationRef:
		name: A
		affinityStrategy:
			policy: Require
			# can be omitted, the default is kubernetes.io/hostname
			require: 
			- "kubernetes.io/hostname"
```



示例2：DataFlow: Op_A, Op_B，Op_B prefers to run in the same regions as Op_A；

```yaml
# Operation B configure the affinity policy as follows
metadata:
	name: B
spec:
	operationRef:
		name: A
		affinityStrategy:
			policy: Require
			prefer: 
			- "topology.kubernetes.io/region"
```



示例3：DataFlow: Op_A, Op_B，Op_A configures special node affinities (e.g., prefer to run on rack-A nodes), Op_B requires  running in the same rack as Op_A;

```yaml
# Operation A configures to run int the rack-A nodes
metadata:
	name: B
spec:
	affinity:
		nodeAffinity：
			preferredDuringSchedulingIgnoredDuringExecution：
				weight: 100,
				preference：
				- matchExpressions：
					- key："label.rack"
					  operator: In
					  values: ["rack-A"]
# Operation B configuration, run in the same rack as Opeartion A
metadata:
	name: B
spec:
	operationRef:
		name: A
		affinityStrategy:
			policy: Require
			require: 
			- "label.rack"
```



## Related
DataOperation's pods do not use webhooks for affinity injection (Serverful/Serverless).
